{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "#pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c74e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to scrape headlines and dates from Crypto News\n",
    "def scrape_crypto_news():\n",
    "    headlines = []\n",
    "    dates = []\n",
    "    for page in range(1, 15):\n",
    "        url = f\"https://crypto.news/page/{page}/?s=xrp\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for h3, date_div in zip(soup.find_all('h3'), soup.find_all('div', class_='search-result-loop__date')):\n",
    "            headline = h3.get_text()\n",
    "            raw_date = date_div.get_text(strip=True).split(\" at \")[0]  # Remove time\n",
    "            parsed_date = datetime.strptime(raw_date, \"%B %d, %Y\").strftime('%d/%m/%Y')\n",
    "            headlines.append(headline)\n",
    "            dates.append(parsed_date)\n",
    "    return headlines, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7740f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to scrape titles and dates from The Crypto Basic\n",
    "def scrape_crypto_basic():\n",
    "    titles = []\n",
    "    dates = []\n",
    "    for page in range(1, 15):\n",
    "        url = f\"https://thecryptobasic.com/tag/ripple/page/{page}/\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for a in soup.find_all('a'):\n",
    "            title = a.find('h3')\n",
    "            date_time = a.find('time', class_='entry-date updated td-module-date')\n",
    "            if title and date_time:\n",
    "                raw_date = date_time['datetime'].split(\"T\")[0]  # Extract date part\n",
    "                parsed_date = datetime.strptime(raw_date, \"%Y-%m-%d\").strftime('%d/%m/%Y')\n",
    "                titles.append(title.get_text())\n",
    "                dates.append(parsed_date)\n",
    "    return titles, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to scrape headlines and dates from Yahoo Finance\n",
    "def scrape_yahoo_finance():\n",
    "    yahoo_headlines = []\n",
    "    dates = []\n",
    "    url = \"https://finance.yahoo.com/quote/XRP-USD/news/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('h3', class_='Mb(5px)')\n",
    "    times = soup.find_all('div', class_='publishing yf-1weyqlp')\n",
    "\n",
    "    for article, time_div in zip(articles[:50], times[:50]):  # Limit to 20 articles\n",
    "        headline = article.get_text()\n",
    "        time_text = time_div.get_text(strip=True).split(\"â€¢\")[-1].strip()\n",
    "        # Calculate date from \"XX hours/days ago\"\n",
    "        today = datetime.today()\n",
    "        if \"hour\" in time_text:\n",
    "            hours_ago = int(re.search(r\"\\d+\", time_text).group())\n",
    "            article_date = today - timedelta(hours=hours_ago)\n",
    "        elif \"day\" in time_text:\n",
    "            days_ago = int(re.search(r\"\\d+\", time_text).group())\n",
    "            article_date = today - timedelta(days=days_ago)\n",
    "        elif \"week\" in time_text:\n",
    "            weeks_ago = int(re.search(r\"\\d+\", time_text).group())\n",
    "            article_date = today - timedelta(weeks=weeks_ago)\n",
    "        elif \"month\" in time_text:\n",
    "            months_ago = int(re.search(r\"\\d+\", time_text).group())\n",
    "            article_date = today - timedelta(days=months_ago * 30)\n",
    "        else:\n",
    "            article_date = today\n",
    "\n",
    "        parsed_date = article_date.strftime('%d/%m/%Y')\n",
    "        yahoo_headlines.append(headline)\n",
    "        dates.append(parsed_date)\n",
    "\n",
    "    return yahoo_headlines, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Combine all scraped data\n",
    "def combine_data():\n",
    "    crypto_news_headlines, crypto_news_dates = scrape_crypto_news()\n",
    "    crypto_basic_titles, crypto_basic_dates = scrape_crypto_basic()\n",
    "    yahoo_finance_headlines, yahoo_finance_dates = scrape_yahoo_finance()\n",
    "\n",
    "    all_headlines = crypto_news_headlines + crypto_basic_titles + yahoo_finance_headlines\n",
    "    all_dates = crypto_news_dates + crypto_basic_dates + yahoo_finance_dates\n",
    "    return all_headlines, all_dates\n",
    "\n",
    "# The rest of the code remains the same except for updated visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72986284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Create a DataFrame and analyze sentiment\n",
    "data = []\n",
    "all_headlines, all_dates = combine_data()\n",
    "for headline, date in zip(all_headlines, all_dates):\n",
    "    cleaned_headline = re.sub(r'\\W', ' ', headline.lower())\n",
    "    textblob_score = TextBlob(cleaned_headline).sentiment.polarity\n",
    "    vader_score = SentimentIntensityAnalyzer().polarity_scores(cleaned_headline)['compound']\n",
    "    average_score = (textblob_score + vader_score) / 2\n",
    "    sentiment_category = (\n",
    "        \"Bullish\" if average_score >= 0.5 else\n",
    "        \"Slightly Bullish\" if 0.2 < average_score < 0.4 else\n",
    "        \"Neutral\" if -0.2 <= average_score <= 0.2 else\n",
    "        \"Slightly Bearish\" if -0.5 <= average_score < -0.2 else\n",
    "        \"Bearish\"\n",
    "    )\n",
    "    data.append({\n",
    "        'headline': headline,\n",
    "        'date': date,\n",
    "        'textblob_score': textblob_score,\n",
    "        'vader_score': vader_score,\n",
    "        'average_score': average_score,\n",
    "        'sentiment_category': sentiment_category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16beccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Save the DataFrame to a CSV file\n",
    "df.to_csv('crypto_headlines_sentiment_analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Visualization with date on the x-axis\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(x=\"date\", y=\"vader_score\", data=df, color=\"blue\", label=\"Vader Score\", ax=ax)\n",
    "sns.barplot(x=\"date\", y=\"textblob_score\", data=df, color=\"orange\", label=\"TextBlob Score\", ax=ax)\n",
    "\n",
    "ax.set_title(\"Sentiment Analysis of Cryptocurrency Headlines\")\n",
    "ax.set_xlabel(\"Dates (DD/MM/YYYY)\")\n",
    "ax.set_ylabel(\"Sentiment Score\")\n",
    "ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels for clarity\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Descriptive Statistics\n",
    "def descriptive_statistics():\n",
    "    print(\"Descriptive Statistics:\\n\")\n",
    "    print(df[['textblob_score', 'vader_score', 'average_score']].describe())\n",
    "\n",
    "descriptive_statistics()\n",
    "\n",
    "# Step 8: Sentiment Distribution Visualizations\n",
    "# TextBlob Sentiment Distribution\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.histplot(df['textblob_score'], bins=30, kde=True, color='blue', label='TextBlob')\n",
    "plt.title('TextBlob Sentiment Distribution')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VADER Sentiment Distribution\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.histplot(df['vader_score'], bins=30, kde=True, color='orange', label='VADER')\n",
    "plt.title('VADER Sentiment Distribution')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TextBlob vs VADER Sentiment Scores\n",
    "plt.figure(figsize=(15, 8))\n",
    "scatter = sns.scatterplot(\n",
    "    x='textblob_score',\n",
    "    y='vader_score',\n",
    "    data=df,\n",
    "    hue='sentiment_category',\n",
    "    palette='coolwarm',\n",
    "    s=100,  # Adjust marker size\n",
    "    edgecolor='black'  # Add an outline for better visibility\n",
    ")\n",
    "\n",
    "# Force all sentiment categories to appear in the legend\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Sentiment Category\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add titles and axis labels\n",
    "plt.title('TextBlob vs VADER Sentiment Scores', fontsize=16)\n",
    "plt.xlabel('TextBlob Sentiment Score', fontsize=12)\n",
    "plt.ylabel('VADER Sentiment Score', fontsize=12)\n",
    "\n",
    "# Add grid and axis lines for clarity\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.axvline(0, color='blue', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Descriptive statistics, sentiment distributions, and comparison visualization complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
